{{ template "chart.header" . }}
{{ template "chart.typeBadge" . }} {{ template "chart.versionBadge" . }}

{{ template "chart.description" . }}

# Table of Contents
<!-- TOC -->

- [helm-watchdog-pod-delete](#helm-watchdog-pod-delete)
- [Table of Contents](#table-of-contents)
- [Prerequisites](#prerequisites)
- [Installing the Chart](#installing-the-chart)
  - [Grant Identity Permissions in GKE (Workload Identity)](#grant-identity-permissions-in-gke-workload-identity)
- [Uninstalling the Chart](#uninstalling-the-chart)
- [Motivation and use cases](#motivation-and-use-cases)
  - [Problem Statement](#problem-statement)
  - [Solution](#solution)
  - [Use Cases](#use-cases)
- [How It Works](#how-it-works)
- [Parameters](#parameters)

<!-- TOC -->

# Prerequisites

- Install the kubectl, helm and helm-docs commands following the instructions of the file [REQUIREMENTS.md](../../REQUIREMENTS.md).

# Installing the Chart

- Access a Kubernetes cluster.

- Change the values according to the need of the environment in ``{{ template "chart.name" . }}/values.yaml`` file. The [Parameters](#parameters) section lists the parameters that can be configured during installation.

Add Helm repository:

```bash
helm repo add {{ template "chart.name" . }} https://aeciopires.github.io/{{ template "chart.name" . }}
```

Update the list helm charts available for installation. This is recommend prior to installation/upgrade:

```bash
helm repo update
```

Get all versions of helm chart:

```bash
helm search repo {{ template "chart.name" . }}/{{ template "chart.name" . }} -l
```

- Test the installation with command:

```bash
helm upgrade --install {{ template "chart.name" . }} -f values.yaml {{ template "chart.name" . }}/{{ template "chart.name" . }} -n {{ template "chart.name" . }} --create-namespace --dry-run
```

- To install/upgrade the chart with the release name `{{ template "chart.name" . }}`:

```bash
helm upgrade --install {{ template "chart.name" . }} -f values.yaml {{ template "chart.name" . }}/{{ template "chart.name" . }} -n {{ template "chart.name" . }} --create-namespace
```

See logs of pod with the follow command:

```bash
kubectl logs -f deploy/{{ template "chart.name" . }} -n {{ template "chart.name" . }}
```

## Grant Identity Permissions in GKE (Workload Identity)

In GKE, access to the cluster may be managed by Workload Identity (instead of the default Kubernetes ServiceAccounts).

To fix this:

- Enable Workload Identity (if required)
- If Workload Identity is enabled in GKE, the Kubernetes ServiceAccount must be linked to a Google Cloud ServiceAccount:

```bash
# Link the Kubernetes ServiceAccount to the GCP ServiceAccount
gcloud iam service-accounts add-iam-policy-binding \
GCP_SERVICE_ACCOUNT@PROJECT.iam.gserviceaccount.com \
--role roles/iam.workloadIdentityUser \
--member "serviceAccount:PROJECT.svc.id.goog[{{ template "chart.name" . }}/{{ template "chart.name" . }}]"
```

- Replace:
  - GCP_SERVICE_ACCOUNT with the Google Cloud ServiceAccount.
  - PROJECT with your project ID.

- This allows the container to use correct credentials within the cluster.

# Uninstalling the Chart

To uninstall/delete the `{{ template "chart.name" . }}` deployment:

```bash
helm uninstall {{ template "chart.name" . }} -n {{ template "chart.name" . }}
```

# Motivation and use cases

## Problem Statement

In Kubernetes, applications running as Pods may sometimes enter an undesired state such as ``CrashLoopBackOff`` or ``Error``. This can happen due to various reasons like memory leaks, unhandled exceptions, or external dependencies failing.

By default, Kubernetes restarts **containers** inside a Pod but does not recreate the entire **Pod** itself. This can lead to issues where the Pod remains stuck in a broken state and requires manual intervention.

Additionally, ``sidecars`` and ``initContainers`` can introduce challenges:

- ``Sidecar containers`` may fail, but Kubernetes only restarts the main application container, leaving the Pod in a partially functional state.
- ``InitContainers`` run only during Pod creation, so if they depend on external services that were unavailable at the time, the Pod can become stuck.
- ``Race conditions with external dependencies`` (e.g., external secrets, databases, message brokers, or API services) may cause startup failures that require a full Pod restart.

## Solution

The **Helm Watchdog Pod Restart** is a lightweight monitoring solution that:

- Periodically monitors all Pods in specified namespaces.
- Detects Pods that are in a CrashLoopBackOff or Error state.
- Automatically deletes these Pods, triggering a fresh restart.
- Supports monitoring all namespaces or a specific list of namespaces.
- Allows excluding certain namespaces (e.g., kube-system, monitoring).
- Ensures sidecar containers and initContainers are properly restarted when needed.
- Helps mitigate race conditions by ensuring Pods are recreated when external dependencies become available.
- Runs as a Kubernetes Deployment using a bitnami/kubectl container.
- Uses Helm for easy deployment and configuration.

## Use Cases

This solution is useful for:

- Ensuring high availability of applications by automatically recovering failed Pods.
- Reducing manual intervention, avoiding the need for SREs/DevOps engineers to manually restart Pods.
- Handling intermittent failures in microservices-based architectures.
- Automating Pod recovery in multi-tenant clusters where different teams manage different namespaces.
- Fixing issues with ``sidecars`` and ``initContainers`` by ensuring Pods are fully restarted instead of remaining in a partially functional state.
- Resolving race conditions caused by unavailable external dependencies at startup, ensuring that Pods retry initialization when dependencies are ready.

# How It Works

The watchdog runs as a single Deployment in Kubernetes.

It continuously checks for Pods in a CrashLoopBackOff or Error state.

When it finds a failed Pod, it deletes it, allowing Kubernetes to schedule a new Pod (if managed by ReplicaSet, Deployment, DemonSet or StatefulSet).

The monitoring interval and namespace filtering can be configured via Helm values.

# Parameters

The following tables lists the configurable parameters of the chart and their default values.

Change the values according to the need of the environment in ``{{ template "chart.name" . }}/values.yaml`` file.

{{ template "chart.valuesTable" . }}
